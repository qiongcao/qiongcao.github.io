<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
<!-- Please delete this script if you use this HTML. -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-143495247-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-143495247-1');
</script>

<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=500">
  <link href="files/stylesheet.css" rel="stylesheet" type="text/css">
  <title>Qiong Cao</title>
  
  <link href="files/css" rel="stylesheet" type="text/css">
</head>

<body>
  <table width="950" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="5%">
            </td> 
            <td width="30%">
              <img src="files/selfie1.jpg" height="224">
            </td>
            <td width="65%" valign="middle">
              <p align="center">
                <name>Qiong Cao</name>
              </p>
              <p align="center">
                <img src="files/email_icon.png" width="21" align="absmiddle">
<a href="mailto:mathqiong2012@gmail.com">mathqiong2012@gmail.com</a>
              <p>
                I am a Research Scientist at JD Explore Academy working with Prof. Dacheng Tao. Formerly I was a Senior Researcher at Tencent Youtu Lab. Before that, I was a Postdoctoral Researcher in the <a href="http://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group (VGG)</a> at the <a href="http://www.robots.ox.ac.uk/">University of Oxford</a>, where I worked with Prof. Andrew Zisserman. </p>

              <p>
                I obtained my PhD in Computer Science from the <a href="http://www.exeter.ac.uk/">University of Exeter</a> under the supervision of Prof. Yiming Ying and Richard Everson. 
              <p> 
                My research interests are in computer vision and deep learning, with a specific interest in human-centric 2D and 3D visual perception and multimodal generation.

				
              <p align="left">
                <a href="files/CV_QiongCao.pdf.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=JYtbNBsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/qiong-cao-67701960"> LinkedIn </a>			  			  
              </p>
            </td>
          </tr>
        </tbody>
        </table>
				
        <br> 
        <heading>Publications</heading><p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
        <tbody><tr>

        <td width="25%"><img src="files/GRAMMAR.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="">
		   <papertitle>GraMMaR: Ground-aware Motion Model for 3D Human Reconstruction.</papertitle>
		 </a> 
         <br>Sihan Ma, <strong>Qiong Cao</strong>, Hongwei Yi, Jing Zhang, Dacheng Tao.<br>
         <em>The ACM Multimedia (ACM MM)</em>, 2023.<br>
         <br>
         </td>
         </tr>
        <tr>         
		
        <td width="25%"><img src="files/talkshow.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="">
		   <papertitle>Generating Holistic 3D Human Motion from Speech.</papertitle>
		 </a> 
         <br>Hongwei Yi, Hualin Liang, Yifei Liu, <strong>Qiong Cao</strong>*, Yandong Wen, Timo Bolkart, Dacheng Tao, Michael J Black*. (*corresponding authors.)<br>
         <em>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023.<br>
         <br>
         </td>
         </tr>
        <tr>         
		
        <td width="25%"><img src="files/Tridet.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="">
		   <papertitle>TriDet: Temporal Action Detection with Relative Boundary Modeling.</papertitle>
		 </a> 
         <br>Dingfeng Shi, Yujie Zhong, <strong>Qiong Cao</strong>*, Lin Ma, Jia Li, Dacheng Tao. (*corresponding authors.)<br>
         <em>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023.<br>
         <br>
         </td>
         </tr>
        <tr>         
		
	<td width="25%"><img src="files/NRMM.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="">
		   <papertitle>Learning Sequence Representations by Non-local Recurrent Neural Memory.</papertitle>
		 </a> 
         <br>Wenjie Pei, Xin Feng, Canmiao Fu, <strong>Qiong Cao</strong>, Guangming Lu and Yu-wing Tai.<br>
         <em>International Journal of Computer Vision (IJCV)</em>, 2022.<br>
         <br>
         </td>
         </tr>
        <tr>         
		
		
	<td width="25%"><img src="files/V2.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="">
		   <papertitle>View Vertically: A Hierarchical Network for Trajectory Prediction via Fourier Spectrums.</papertitle>
		 </a> 
         <br>Conghao Wong, Beihao Xia, Ziming Hong, Qinmu Peng, Wei Yuan, <strong>Qiong Cao</strong>, Yibo Yang, Xinge You.<br>
         <em>European Conference on Computer Vision (ECCV)</em>, 2022.<br>
         <br>
         </td>
         </tr>
        <tr>         
		
	<td width="25%"><img src="files/ReAct.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://arxiv.org/pdf/2207.07097.pdf">
		   <papertitle>ReAct: Temporal Action Detection with Relational Queries.</papertitle>
		 </a> 
         <br>Dingfeng Shi, Yujie Zhong, <strong>Qiong Cao</strong>*, Jing Zhang, Lin Ma, Jia Li*, Dacheng Tao. (*corresponding authors.)<br>
         <em>European Conference on Computer Vision (ECCV)</em>, 2022.<br>
         <br>
         </td>
         </tr>
        <tr> 

	<td width="25%"><img src="files/DearKD.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_DearKD_Data-Efficient_Early_Knowledge_Distillation_for_Vision_Transformers_CVPR_2022_paper.pdf">
		   <papertitle>DearKD: Data-Efficient Early Knowledge Distillation for Vision Transformers.</papertitle>
		 </a> 
         <br>Xianing Chen, <strong>Qiong Cao</strong>*, Yujie Zhong, Jing Zhang, Shenghua Gao*, Dacheng Tao. (*corresponding authors.)<br>
         <em>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022.<br>
         <br>
         </td>
         </tr>
        <tr> 
		
	<td width="25%"><img src="files/reid.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://arxiv.org/abs/1908.10535">
		   <papertitle>Push for center learning via orthogonalization and subspace masking for person re-identification.</papertitle>
		 </a> 
         <br>Weinong Wang, Wenjie Pei, <strong>Qiong Cao</strong>, Shu Liu, Xiaoyong Shen, Yu-Wing Tai.<br>
         <em>IEEE Transactions on Image Processing (TIP)</em>, 2021.<br>
         <br>
         </td>
         </tr>
        <tr> 
		
	<td width="25%"><img src="files/nlnm.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://arxiv.org/abs/1908.09535">
		   <papertitle>Non-local Recurrent Neural Memory for Supervised Sequence Modeling.</papertitle>
		 </a> 
         <br>Canmiao Fu, Wenjie Pei, <strong>Qiong Cao</strong>, Chaopeng Zhang, Yong Zhao, Xiaoyong Shen, Yu-Wing Tai.<br>
         <em>International Conference on Computer Vision (ICCV)</em>, 2019.<br>
         <br>
         </td>
         </tr>
        <tr> 		
		
        <td width="25%"><img src="files/MMFace.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://paperswithcode.com/paper/mmface-a-multi-metric-regression-network-for">
		   <papertitle>MMFace: A Multi-Metric Regression Network for Unconstrained Face Reconstruction.</papertitle>
		 </a> 
         <br>Hongwei Yi, Chen Li, <strong>Qiong Cao</strong>, Xiaoyong Shen, Sheng Li, Guoping Wang, Yu-Wing Tai.<br>
         <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2019.<br>
         <br>
         </td>
         </tr>
        <tr> 
		
        <td width="25%"><img src="files/videoface.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://ieeexplore.ieee.org/abstract/document/8590759">
		   <papertitle>Automated video face labelling for films and TV material.</papertitle>
		 </a> 
         <br>Omkar Parkhi, Esa Rahtu, <strong>Qiong Cao</strong>, Andrew Zisserman.<br>
         <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2018.<br>
         <br>
         </td>
         </tr>
        <tr> 

        <td width="25%"><img src="files/vggface2_icon.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://ieeexplore.ieee.org/abstract/document/8373813">
		   <papertitle>Vggface2: A dataset for recognising faces across pose and age.</papertitle>
		 </a> 
         <br><strong>Qiong Cao</strong>, Li Shen, Weidi Xie, Omkar M Parkhi, Andrew Zisserman.<br>
         <em>IEEE International Conference on Automatic Face and Gesture Recognition (FG)</em>, 2018.
         <br> <a href="https://academictorrents.com/details/535113b8395832f09121bc53ac85d7bc8ef6fa5b">Download VGGFace2 
	<br>
		 
         </td>
         </tr>
        <tr> 

        <td width="25%"><img src="files/templateface.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://arxiv.org/pdf/1603.03958.pdf">
		   <papertitle>Template adaptation for face verification and identification.</papertitle>
		 </a> 
         <br>Nate Crosswhite, Jeffrey Byrne, Omkar M Parkhi, Chris Stauffer, <strong>Qiong Cao</strong>, Andrew Zisserman.<br>
         <em>IEEE International Conference on Automatic Face and Gesture Recognition (FG)</em>, 2017.<br>
         <br>
         </td>
         </tr>
        <tr> 

        <td width="25%"><img src="files/bounds.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://rd.springer.com/article/10.1007/s10994-015-5499-7">
		   <papertitle>Generalization bounds for metric and similarity learning.</papertitle>
		 </a> 
         <br><strong>Qiong Cao</strong>, Zheng-Chu Guo, Yiming Ying.<br>
         <em>Machine Learning</em>, 2016.<br>
         <br>
         </td>
         </tr>
        <tr> 

        <td width="25%"><img src="files/SubSML.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Cao_Similarity_Metric_Learning_2013_ICCV_paper.pdf">
		   <papertitle>Similarity metric learning for face recognition.</papertitle>
		 </a> 
         <br><strong>Qiong Cao</strong>, Yiming Ying, Peng Li.<br>
         <em>International Conference on Computer Vision (ICCV)</em>, 2013.<br>
         <br>
         </td>
         </tr>
        <tr>         

        <td width="25%"><img src="files/DMLp.png" width="200">
          </td>
         <td width="75%" valign="middle"> 
         <a href="https://rd.springer.com/chapter/10.1007/978-3-642-33460-3_24">
		   <papertitle>Distance metric learning revisited.</papertitle>
		 </a> 
         <br><strong>Qiong Cao</strong>, Yiming Ying, Peng Li.<br>
         <em>European Conference on Machine Learning & Principles and Practice of Knowledge Discovery (ECML PKDD)</em>, 2012.<br>
         <br>
         </td>
         </tr>
        <tr>         
		
  </tbody></table>
  <br>
  <br>

        <heading>Doctoral Thesis</heading>
        <p> </p>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
              <a href="https://ore.exeter.ac.uk/repository/handle/10871/18662">
                <papertitle>Some Topics on Similarity Metric Learning.</papertitle>
              </a>
              <br>
              <strong>Qiong Cao</strong>, Unversity of Exeter, 2015. 
              <br>
        </table>
        <p> </p>
        <br>
        <br>
		
        <heading> Academic Experience </heading>
          <ul style="list-style-type:circle;">
          <li style="margin: 8px 0;">
          Conference Review: NIPS, CVPR, AAAI, AISTATS. </li>
          <li style="margin: 8px 0;">
          Journal Review: TPAMI, PR. </li>
          </ul>
		    <br>
        <br>
		 
        <heading>Awards</heading>
          <ul style="list-style-type:circle;">
          <li style="margin: 8px 0;">
          Nanshan Pilot Talent, Shenzhen, China, Oct 2018. </li>
          <li style="margin: 8px 0;">
          Overseas High-Caliber Personnel (Level C), Shenzhen, China, Feb 2018. </li>
    		  <li style="margin: 8px 0;">
          EPSRC Doctor Training Grant (DTG), UK, Dec 2011. </li>
          </ul>
          <br>
          <br>
          <br>
         <p align="right">Last Update: April, 2023</p>
         <p align="right">Published with <a href="https://pages.github.com">GitHub Pages</a></p>
		 
    </tbody>
    </table>
          <br>
          <br>
</body></html>
